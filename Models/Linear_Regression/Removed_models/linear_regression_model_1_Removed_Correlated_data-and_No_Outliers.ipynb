{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32638a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tabulate import tabulate\n",
    "from statsmodels.tools import add_constant\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f15f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>payment_sequential</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>payment_installments</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>review_score</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>state</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "      <th>sales_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-09-13 08:59:00</td>\n",
       "      <td>5</td>\n",
       "      <td>28013</td>\n",
       "      <td>18</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>55.9</td>\n",
       "      <td>17.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-06-28 11:52:00</td>\n",
       "      <td>5</td>\n",
       "      <td>75800</td>\n",
       "      <td>8</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>55.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>64.9</td>\n",
       "      <td>18.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-18 10:25:00</td>\n",
       "      <td>4</td>\n",
       "      <td>30720</td>\n",
       "      <td>10</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>58.9</td>\n",
       "      <td>16.17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-01 18:38:00</td>\n",
       "      <td>5</td>\n",
       "      <td>83070</td>\n",
       "      <td>17</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4244733e06e7ecb4970a6e2683c13e61</td>\n",
       "      <td>58.9</td>\n",
       "      <td>13.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-10 21:48:00</td>\n",
       "      <td>5</td>\n",
       "      <td>36400</td>\n",
       "      <td>10</td>\n",
       "      <td>cool_stuff</td>\n",
       "      <td>650.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  item_price  freight_value  \\\n",
       "0  4244733e06e7ecb4970a6e2683c13e61        58.9          13.29   \n",
       "1  4244733e06e7ecb4970a6e2683c13e61        55.9          17.96   \n",
       "2  4244733e06e7ecb4970a6e2683c13e61        64.9          18.33   \n",
       "3  4244733e06e7ecb4970a6e2683c13e61        58.9          16.17   \n",
       "4  4244733e06e7ecb4970a6e2683c13e61        58.9          13.29   \n",
       "\n",
       "   payment_sequential  payment_type  payment_installments  \\\n",
       "0                   1             1                     2   \n",
       "1                   1             0                     1   \n",
       "2                   1             1                     2   \n",
       "3                   1             1                     3   \n",
       "4                   1             1                     4   \n",
       "\n",
       "  order_purchase_timestamp  review_score  postal_code  state  \\\n",
       "0      2017-09-13 08:59:00             5        28013     18   \n",
       "1      2017-06-28 11:52:00             5        75800      8   \n",
       "2      2018-05-18 10:25:00             4        30720     10   \n",
       "3      2017-08-01 18:38:00             5        83070     17   \n",
       "4      2017-08-10 21:48:00             5        36400     10   \n",
       "\n",
       "  product_category_name  product_weight_g  product_length_cm  \\\n",
       "0            cool_stuff             650.0               28.0   \n",
       "1            cool_stuff             650.0               28.0   \n",
       "2            cool_stuff             650.0               28.0   \n",
       "3            cool_stuff             650.0               28.0   \n",
       "4            cool_stuff             650.0               28.0   \n",
       "\n",
       "   product_height_cm  product_width_cm  sales_revenue  \n",
       "0                9.0              14.0           58.9  \n",
       "1                9.0              14.0           55.9  \n",
       "2                9.0              14.0           64.9  \n",
       "3                9.0              14.0           58.9  \n",
       "4                9.0              14.0           58.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data \n",
    "df = pd.read_csv('Olist_remove_no_correlated_no_item2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23632125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Select the columns you're interested in\n",
    "cols = [ 'item_price']\n",
    "\n",
    "# Calculate z-scores\n",
    "z_scores = np.abs(stats.zscore(df[cols]))\n",
    "\n",
    "# Create a new DataFrame with the z-scores\n",
    "df_z_scores = pd.DataFrame(z_scores, columns=cols, index=df.index)\n",
    "\n",
    "# Join the z-scores DataFrame with the original DataFrame\n",
    "df = df.join(df_z_scores, rsuffix='_zscore')\n",
    "\n",
    "# Keep only rows where all z-scores are less than 3\n",
    "df = df[(df[[col + '_zscore' for col in cols]] < 3).all(axis=1)]\n",
    "\n",
    "# Now you can drop the z-score columns\n",
    "df = df.drop(columns=[col + '_zscore' for col in cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4628cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the defined columns from the dataframe to form feature set 'X'.\n",
    "X = df.drop(['sales_revenue', 'order_purchase_timestamp'], axis=1)\n",
    "\n",
    "# Assign 'sales_revenue' column as the target variable 'y'.\n",
    "y = df['sales_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ba267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              product_id  Actual   Predicted\n",
      "107507  aeb767ca82c5a6cca8bbac33c4e21579  136.00   50.212283\n",
      "40414   0da9ffd92214425d880de3f94e74ce39  112.00  133.055808\n",
      "51022   2f13d1dc8b4e1d9d8027be50339546a9  105.00  121.311643\n",
      "82904   3b66a296f7f9d4a5aa79ca89f460af73   33.80   38.910909\n",
      "105162  9523f1a3e7db9e38d55379435bd450c9  134.17  147.530085\n",
      "...                                  ...     ...         ...\n",
      "5577    389d119b48cf3043d311335e499d9c6b   99.80   55.492345\n",
      "41975   6ec26071510e1cf38d6988f473f8d7a5   69.90   74.849187\n",
      "48747   67bd616e1ba0d3d3e8545f3113b0140d   14.49   14.865700\n",
      "35601   5ad2b7b30050dd8aa51c2fed1db13e22   99.00  114.671188\n",
      "69018   730f1927f42fda4370209c28203eb0ab   55.96   12.980409\n",
      "\n",
      "[22658 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Keep a copy of the Product IDs for the test set before dropping from X\n",
    "X_Product_IDs = X['product_id'].copy()\n",
    "\n",
    "# Drop the Product ID from X\n",
    "X = X.drop('product_id', axis=1)\n",
    "\n",
    "# Split the data into train/test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Split train_val set into separate training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=0)\n",
    "\n",
    "# Define preprocessing for numerical columns (scale them)\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to train a linear regression model on the training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the fitted model\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Create a DataFrame for the predictions, indexed by Product ID\n",
    "df_predictions = pd.DataFrame({\n",
    "    'product_id': X_Product_IDs.loc[X_test.index],\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test\n",
    "})\n",
    "\n",
    "print(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91562b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions on the train, validation, and test sets\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate R-squared scores\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_val = r2_score(y_val, y_pred_val)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print('Train R2 score: ', r2_train)\n",
    "print('Validation R2 score: ', r2_val)\n",
    "print('Test R2 score: ', r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed1635c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_price', 'freight_value', 'payment_sequential', 'payment_type',\n",
       "       'payment_installments', 'review_score', 'postal_code', 'state',\n",
       "       'product_category_name', 'product_weight_g', 'product_length_cm',\n",
       "       'product_height_cm', 'product_width_cm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the coefficients\n",
    "coef_df = pd.DataFrame(pipeline.named_steps['regressor'].coef_, X.columns, columns=['Coefficient'])\n",
    "\n",
    "# Append the intercept\n",
    "coef_df = coef_df.append(pd.DataFrame([pipeline.named_steps['regressor'].intercept_], ['Intercept'], columns=['Coefficient']))\n",
    "\n",
    "# Display the dataframe\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe1b513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Actual   Predicted\n",
      "107507  136.00   50.212283\n",
      "40414   112.00  133.055808\n",
      "51022   105.00  121.311643\n",
      "82904    33.80   38.910909\n",
      "105162  134.17  147.530085\n",
      "...        ...         ...\n",
      "5577     99.80   55.492345\n",
      "41975    69.90   74.849187\n",
      "48747    14.49   14.865700\n",
      "35601    99.00  114.671188\n",
      "69018    55.96   12.980409\n",
      "\n",
      "[22658 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_compare = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_test})\n",
    "print(df_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "# vif = df\n",
    "# vif[\"Feature\"] = X.columns\n",
    "# vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd9b9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 25.355739731063732\n",
      "Mean Squared Error: 4941.4963213432075\n",
      "Root Mean Squared Error: 70.29577740763102\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred_test))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_test))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d9e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sales_revenue   Predicted\n",
      "107507         136.00   50.212283\n",
      "40414          112.00  133.055808\n",
      "51022          105.00  121.311643\n",
      "82904           33.80   38.910909\n",
      "105162         134.17  147.530085\n",
      "...               ...         ...\n",
      "5577            99.80   55.492345\n",
      "41975           69.90   74.849187\n",
      "48747           14.49   14.865700\n",
      "35601           99.00  114.671188\n",
      "69018           55.96   12.980409\n",
      "\n",
      "[22658 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe for test set predictions\n",
    "df_test_predictions = pd.DataFrame(y_pred_test, columns=['Predicted'], index=y_test.index)\n",
    "\n",
    "# Merge this dataframe with the actuals, using the common index\n",
    "df_test_combined = y_test.to_frame().join(df_test_predictions)\n",
    "\n",
    "# Now 'sales_revenue' is your actual values and 'Predicted' is the model's predictions\n",
    "print(df_test_combined[['sales_revenue', 'Predicted']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a336bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22658,)\n",
      "(22658,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7116e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6b052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98176e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 23.53%\n",
      "Mean Percentage Error (MPE): -12.01%\n",
      "Percentage Root Mean Squared Error (PRMSE): 60.32%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_test and y_pred_test are your actual and predicted values\n",
    "\n",
    "# Calculate MAPE\n",
    "mape = np.mean(np.abs((y_test - y_pred_test) / y_test)) * 100\n",
    "\n",
    "# Calculate MPE\n",
    "mpe = np.mean((y_test - y_pred_test) / y_test) * 100\n",
    "\n",
    "# Calculate PRMSE\n",
    "prmse = (np.sqrt(np.mean((y_test - y_pred_test) ** 2)) / np.mean(y_test)) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Percentage Error (MAPE): {:.2f}%\".format(mape))\n",
    "print(\"Mean Percentage Error (MPE): {:.2f}%\".format(mpe))\n",
    "print(\"Percentage Root Mean Squared Error (PRMSE): {:.2f}%\".format(prmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "498fb6c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming y_train and y_test are the actual target values\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mregressor\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m      5\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      7\u001b[0m train_mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_train, y_train_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'regressor' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming y_train and y_test are the actual target values\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c34aec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_mse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m----> 3\u001b[0m train_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mtrain_mse\u001b[49m)\n\u001b[0;32m      4\u001b[0m test_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(test_mse)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain RMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_rmse)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_mse' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13a3c9dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'sports_leisure'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      9\u001b[0m regressor \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 10\u001b[0m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Training the algorithm\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# To retrieve the intercept:\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntercept:\u001b[39m\u001b[38;5;124m\"\u001b[39m, regressor\u001b[38;5;241m.\u001b[39mintercept_)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'sports_leisure'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)  # Training the algorithm\n",
    "\n",
    "# To retrieve the intercept:\n",
    "print(\"Intercept:\", regressor.intercept_)\n",
    "\n",
    "# For retrieving the slope:\n",
    "print(\"Coefficients:\", regressor.coef_)\n",
    "\n",
    "y_pred_train = regressor.predict(X_train)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy (R-squared) for train and test sets\n",
    "print(\"Train R-squared:\", r2_score(y_train, y_pred_train))\n",
    "print(\"Test R-squared:\", r2_score(y_test, y_pred_test))\n",
    "\n",
    "# Calculate the residuals\n",
    "residuals = y_test - y_pred_test\n",
    "\n",
    "\n",
    "# Plotting the residuals against the predicted values with color-coded data points\n",
    "plt.scatter(y_pred_test, residuals, alpha=0.5, c=residuals, cmap='coolwarm')\n",
    "plt.axhline(y=0, color='red', linestyle='--')  # Add a horizontal line at y=0\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs. Predicted Values (Homoscedasticity)')\n",
    "plt.colorbar(label='Residuals')  # Add a colorbar indicating the range of residuals\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bbe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming residuals is your residual data\n",
    "\n",
    "# Create a DataFrame with residuals\n",
    "residuals_data = pd.DataFrame({'Residuals': residuals})\n",
    "\n",
    "# Count the occurrences of each residual value\n",
    "residuals_counts = residuals_data['Residuals'].value_counts()\n",
    "\n",
    "# Display the residuals counts as a table\n",
    "print(residuals_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb118c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(df['payment_value'], df['sales_revenue'])\n",
    "# plt.xlabel('payment_value')\n",
    "# plt.ylabel('sales_revenue')\n",
    "# plt.title('Scatter plot of payment_value against sales_revenue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "dw = durbin_watson(residuals)\n",
    "print('Durbin-Watson:', dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c165b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import probplot\n",
    "\n",
    "probplot(residuals, plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the predicted values and residuals\n",
    "residuals_df = pd.DataFrame({'Predicted Values': y_pred_test, 'Residuals': residuals})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(residuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027b3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with 'order_purchase_timestamp' information\n",
    "df_test_combined = df_test_combined.join(df['order_purchase_timestamp'])\n",
    "\n",
    "# Convert 'order_purchase_timestamp' to datetime if it isn't already\n",
    "df_test_combined['order_purchase_timestamp'] = pd.to_datetime(df_test_combined['order_purchase_timestamp'])\n",
    "\n",
    "# Set 'order_purchase_timestamp' as the index\n",
    "df_test_combined.set_index('order_purchase_timestamp', inplace=True)\n",
    "\n",
    "# Sort the DataFrame by the index\n",
    "df_test_combined.sort_index(inplace=True)\n",
    "\n",
    "# Now df_test_combined contains both the actual and predicted sales revenue, in chronological order\n",
    "print(df_test_combined[['sales_revenue', 'Predicted']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the dataframe to monthly frequency, aggregating with mean\n",
    "df_monthly = df_test_combined.resample('M').mean()\n",
    "\n",
    "# Create a line plot of actual and predicted values\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_monthly.index, df_monthly['sales_revenue'], label='Actual')\n",
    "plt.plot(df_monthly.index, df_monthly['Predicted'], label='Predicted')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Sales Revenue')\n",
    "plt.title('Actual vs Predicted Sales Revenue Over Time (Monthly)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
